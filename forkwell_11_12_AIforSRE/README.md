# テーマ
OpenAIの躍進により、我々の仕事はAIとはきっても切り離せない時代となりました。私は正直10年前にこうなることをまるで予想できませんでした。 AIの発展により、今後加速度的に変化していくであろうエンジニアの仕事について、SREとしての立場から考えてみたいと思います。

# 主張したいこと
　AIの進化によって、エンジニアを取り巻く環境には大きないくつかの変化があったと考えています。その中から3点紹介します。

　1つ目はコーディング作業をAIが支援することにより、技術力を資本とした成果の差がより大きくなった。これはAIで生成した成果物の真贋を確かめるためには、利用者の基礎知識が大きく影響することから、基礎知識が豊富なエンジニアは、それを資本により大きな成果を出せるようになったこと。

　2つ目は現時点では優れたAIを開発するには、巨大資本が必要であり、いくつかの一握りの企業だけが状況を左右できる技術になりつつあり、AIそのものがプラットフォームのような状況になりつつあること。

　3つ目はAIのプラットフォーム化に伴い、事業分析用のSQLを生成するなどのいままでエンジニアの作業領域であったような業務においても、別の職種がオーバラップしつつあること。なお、本件においては1点目の真贋を確かめうるか否かという条件があり、比較的自明な要件にのみ適用されている。

　これらの変化を条件としてみた場合に、話し手の主張としては、エンジニアのやるべきことはそんなに変化はなく、基礎知識を体系的に学び、それを資本にAIを活用し、多くのエンジニアはAIをプラットフォームとして受け入れて、これまでのiOSやAndroid、AWS、GCPと同じようにうまく利用するための技術を生み出していく方向になると考える。また本セッションで述べるAIはLLMを指し、LLMは一般的には確率で正解を導き出すものであることから、そういった技術をどういった領域に適用するのが良いかということについても述べたい。

===

# 大規模言語モデル(LLM)
## LLMとは？
　**LLM（Large Language Model、大規模言語モデル）**は、膨大なテキストデータを用いて自然言語処理タスクを行うために設計された機械学習モデルです。特に、OpenAIが2022年に公開したChatGPTが注目され、大規模言語モデル（LLM）の概念が広く知られるようになりました。

　言語モデルは、与えられた文脈に基づいて次に来る単語やフレーズの出現確率を予測します。たとえば、「今日の天気は」の後に続く言葉として「晴れ」「カレーパン」「月曜日」などの選択肢がある場合、文脈に最も自然な「晴れ」が高い確率で選ばれる仕組みです。この予測は、文脈や文法、論理の整合性を考慮して行われます。

　ChatGPTのようなLLMは、単に単語を並べるだけでなく、文脈を理解し、自然な会話や複雑な質問への回答が可能です。これは、自己回帰的に次の単語を生成し続ける高度なプロセスと膨大な学習データによって実現されています。このため、LLMは、質問応答、文章生成、要約といった多様なタスクでの応用が進んでいます。

## LLMが生んだ変化
　LLMの登場によって、話し手の働き方においても大きな変化が起きました。

### コーディング作業などの自動化
　仕様を自然言語で記述したり、コードの一部をサンプルとして示すことで、必要な実装やテストを高い精度で記述してくれることで、高度な並列作業が可能になりました。

### 文章の要約や解説
　技術文章やSlackなどのテキストを扱うときに、これまでは技術的に理解が難しいことであったり、内容が膨大であったりして、どうしても読み解くのに時間がかかっていたものについて、かなり高い精度で要約が出来たり、解説が受けれるようになったことでインプットの効率が上がっています。
### 画像、動画生成
　昨今Xなどでもよく見かけますが、あるキーワードや文章をもとに、それを想起するような画像や、動画を自動で生成できるようになりました。OpenAIが公開した[sora](https://openai.com/index/sora/)の動画を見て、驚いた方も多くいらっしゃると思います。

### バックオフィスの作業効率化
　わかりやすい例として、これまで事業分析用の高度なSQLの生成の多くはエンジニアがディレクターなどから依頼を受けて作成することが少なくありませんでしたが、ChatGPTやGeminiに対してスキーマの情報を与えて、いくつかの仕様を伝えるだけで、大体のSQLは自動で生成されるようになりました。また話し手の所属しているGMOペパボにおいては [@khiroyuki1993](https://x.com/khiroyuki1993) が開発している [tbls-ask-agent-slack](https://github.com/kromiii/tbls-ask-agent-slack) を用いて、[tbls](https://github.com/k1LoW/tbls) のスキーマ情報を利用して、SQLをSlack上で自動生成できる仕組みがあります。

# LLMを利用したサービスの事例
　LLMの発展に伴い、現在ではそれを利用した多くのサービスが提供されています。いくつかをピックアップして紹介します。
## コーディングに特化したエディタ
### Cursor
## 推薦システム
### SUZURIのスリスリくんチャット
## ユーザーの入力補助
### B/43のレシート自動読み取り
### カラーミーの商品紹介の自動作成

# Site Reliability Engineering(SRE)
## SREとは？
## SREの役割
### モニタリングと可観測性の向上
### インシデント管理と復旧対応
### 自動化と効率化

# SREとLLMの関わり
## SREの業務とLLM
### アラートの分析
### オペレーションの補助
#### Terraform定義などの自動生成
#### afaの紹介
### 技術の影響範囲の拡張
#### LLMを活用して生み出す、MLを用いたアクセス制御

# エンジニアの生存戦略
## どのような仕事が残るか？
### 出力の真贋を見極める
### LLMのグルー実装としての人類
## LLMが今はまだあまり向かないこと
### バリデーション
### 決定となること
## この先LLMはどうなっていくか
### プラットフォームとしてのLLM
### ローカル実行されるLLM
## この先、話し手はどうしていくか
### 継続的な基礎知識の研鑽
### プラットフォームとしてのLLM活用
### 情報の真贋を見る力を養う
