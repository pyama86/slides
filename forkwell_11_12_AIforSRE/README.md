# テーマ
OpenAIの躍進により、我々の仕事はAIとはきっても切り離せない時代となりました。私は正直10年前にこうなることをまるで予想できませんでした。 AIの発展により、今後加速度的に変化していくであろうエンジニアの仕事について、SREとしての立場から考えてみたいと思います。

# 主張したいこと
　AIの進化によって、エンジニアを取り巻く環境には大きないくつかの変化があったと考えています。その中から3点紹介します。

　1つ目はコーディング作業をAIが支援することにより、技術力を資本とした成果の差がより大きくなった。これはAIで生成した成果物の真贋を確かめるためには、利用者の基礎知識が大きく影響することから、基礎知識が豊富なエンジニアは、それを資本により大きな成果を出せるようになったこと。

　2つ目は現時点では優れたAIを開発するには、巨大資本が必要であり、いくつかの一握りの企業だけが状況を左右できる技術になりつつあり、AIそのものがプラットフォームのような状況になりつつあること。

　3つ目はAIのプラットフォーム化に伴い、事業分析用のSQLを生成するなどのいままでエンジニアの作業領域であったような業務においても、別の職種がオーバラップしつつあること。なお、本件においては1点目の真贋を確かめうるか否かという条件があり、比較的自明な要件にのみ適用されている。

　これらの変化を条件としてみた場合に、話し手の主張としては、エンジニアのやるべきことはそんなに変化はなく、基礎知識を体系的に学び、それを資本にAIを活用し、多くのエンジニアはAIをプラットフォームとして受け入れて、これまでのiOSやAndroid、AWS、GCPと同じようにうまく利用するための技術を生み出していく方向になると考える。また本セッションで述べるAIはLLMを指し、LLMは一般的には確率で正解を導き出すものであることから、そういった技術をどういった領域に適用するのが良いかということについても述べたい。

***

# 大規模言語モデル(LLM)
## LLMとは？
　**LLM（Large Language Model、大規模言語モデル**は、膨大なテキストデータを用いて自然言語処理タスクを行うために設計された機械学習モデルです。特に、OpenAIが2022年に公開したChatGPTが注目され、大規模言語モデル（LLM）の概念が広く知られるようになりました。

　言語モデルは、与えられた文脈に基づいて次に来る単語やフレーズの出現確率を予測します。たとえば、「今日の天気は」の後に続く言葉として「晴れ」「カレーパン」「月曜日」などの選択肢がある場合、文脈に最も自然な「晴れ」が高い確率で選ばれる仕組みです。この予測は、文脈や文法、論理の整合性を考慮して行われます。

　ChatGPTのようなLLMは、単に単語を並べるだけでなく、文脈を理解し、自然な会話や複雑な質問への回答が可能です。これは、自己回帰的に次の単語を生成し続ける高度なプロセスと膨大な学習データによって実現されています。このため、LLMは、質問応答、文章生成、要約といった多様なタスクでの応用が進んでいます。

## LLMが生んだ変化
　LLMの登場によって、話し手の働き方においても大きな変化が起きました。

### コーディング作業などの自動化
　自然言語で仕様を伝えたり、コードの一部をサンプルとして示すことで、必要な実装やテストを高精度で生成できます。これにより、エンジニアの作業効率が大幅に向上しました。

### 文章の要約や解説
  技術的に難解な文章や膨大な量のテキストも、LLMを使えば高い精度で要約や解説が可能です。これにより、情報のインプット効率が向上し、重要な内容を素早く把握できるようになりました。

### 画像、動画生成
　現在、XなどのSNSでもよく目にしますが、キーワードや文章をもとに、それを表現した画像や動画を自動生成する技術が進んでいます。例えば、OpenAIが公開した[sora](https://openai.com/index/sora/)はその一例で、視覚的なインパクトも話題を呼んでいます。

### バックオフィスの作業効率化
　例えば、事業分析用のSQL生成では、以前はディレクターがエンジニアに依頼してSQLを作成することが多くありました。しかし、ChatGPTやGeminiにスキーマ情報と仕様を伝えるだけで、ある程度のSQLを自動生成できるようになりました。また、GMOペパボでは [@khiroyuki1993](https://x.com/khiroyuki1993) さんが開発した [tbls-ask-agent-slack](https://github.com/kromiii/tbls-ask-agent-slack) を使い、[tbls](https://github.com/k1LoW/tbls) のスキーマ情報を基にSlack上でSQLを自動生成する仕組みが整備されています。

# LLMを利用したサービスの事例
　LLMの進化に伴い、多くのサービスがLLMを取り入れた機能を提供しています。ここでは、その中からいくつかを紹介します。
## コーディングに特化したエディタ
　エンジニアが日々の活動において最も恩恵を受けるであろうエディタについて紹介します。

### GitHub Copilot
　GitHub Copilotは、OpenAIとGitHubが共同開発したAIベースのコーディングアシスタントで、Visual Studio Codeやvimなどのエディタと統合して利用できます。エンジニアが日々のコーディング作業で次のコードを考える手間を省き、効率的に作業できるようサポートする点が特徴です。

Copilotは大規模言語モデル（LLM）を活用し、ユーザーの入力や現在のコードのコンテキストに応じて、次に必要となるコードの一部を予測・提案します。例えば、関数の概要をコメントとして記述するだけで、Copilotがその関数の実装を生成してくれるため、開発スピードが格段に向上します。

さらに、一般的なコーディングパターンやAPIの使い方も理解しているため、複雑なロジックの構築やAPIドキュメントの参照も減らせます。以下は、Copilotの主な特徴です。

コード補完: 単純なコード補完だけでなく、関数全体や複雑なロジックも提案。
コメントからのコード生成: コメントからそのままコードを自動生成。
コンテキスト理解: プロジェクト全体のファイルやリポジトリのコンテキストをもとに提案を行い、一貫性のあるコードをサポート。
GitHub Copilotは、エンジニアの思考をサポートしながら、効率的にコーディングできる環境を提供することで、日常の開発作業を加速させる強力なエディタツールといえます。

### Cursor
  Cursorは、Visual Studio Codeをベースに開発されたAI統合エディタです。対話的にコードを推薦し、統合環境であるため、リポジトリのリソースやドキュメントへのアクセスも容易な点が特徴です。
  前述のCopilotと比較して、プラグインベースではなく、エディタそのものにAI機能が統合されていることが強みだと思います。

## 推薦システム
　推薦システムも、旧来は機械学習をもちいたものが多かったですが、昨今ではLLMを活用したもの増えてきました。
### SUZURIのスリスリくんチャット
　GMOペパボが提供するSUZURIでは、キャラクター「スリスリくん」と会話しながら、ユーザーに適した商品を提案する機能があります。内部では、RAGを活用し、ユーザーに適切な検索ワードを生成、それに基づいて検索結果を推薦する構造になっています。
## ユーザーの入力補助
  OCRとLLMを組み合わせるケースや、これまで利用者が一から文章を作成していた場面でも、LLMの導入が進んでいます。
### B/43のレシート自動読み取り
　先日公開された、B/43の[レシート自動読み取り](https://b43.jp/news/entry/feature-update-self-input) も内部でLLMを活用していることが推測されます。これは話し手がプレスリリースなどを読んだ推測ですが、OCRで読み取った文字列を、LLMにクエリすることで様々なメタ情報を保管していると考えています。

### カラーミーショップにおける商品紹介コンテンツの自動作成
　GMOペパボが提供するECカートサービス「カラーミーショップ」では、ショップオーナーがSNSなどで商品を紹介する際に利用できる文章を自動生成する[カラーミーAIアシスタント（β）](https://help.shop-pro.jp/hc/ja/articles/15000133055123-%E3%82%AB%E3%83%A9%E3%83%BC%E3%83%9F%E3%83%BCAI%E3%82%A2%E3%82%B7%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%88-%CE%B2)が提供されています。この機能は、商品情報をもとに最適な紹介文を生成します。

# Site Reliability Engineering (SRE)
　このセッションのテーマの1つであるSREについて、その役割や重要性について紹介します。SREは、システムの可用性、パフォーマンス、効率性を保つための専任職であり、エンジニアリングと運用の融合によって組織の信頼性を高める役割を担っています。

## SREとは？
　SREはGoogleが提唱したシステム運用の方法論で、システム運用にソフトウェア・エンジニアリングの視点を取り入れ、プロダクション環境での信頼性を向上させることを目的としています。主に、インシデントの予防や対応、運用の自動化などを通じて、ビジネスやサービスの安定性を支えます。

## SREの役割
　SREの役割は多岐にわたりますが、主に以下の3つの分野に大別されます。

### モニタリングと可観測性の向上
　システムの状態をリアルタイムで監視し、異常を早期に検知するためのモニタリングや可観測性を高める取り組みです。単なる監視ではなく、システム内の隠れた問題を可視化し、必要に応じて適切なアクションを取るための体制を整えます。

### インシデント管理と復旧対応
　インシデント発生時に迅速に復旧するだけでなく、根本原因の特定や、同様の問題が再発しないようなプロアクティブな対応が求められます。SREは、インシデントの予防策と復旧のプロセスを改善し、システムの信頼性を高める役割を担っています。

### 自動化と効率化
　ルーチン作業の自動化や効率化によって、エンジニアの手作業を減らし、再現性と信頼性の向上を図ります。これにより、チームはより複雑で価値の高い課題に集中でき、システム全体の品質とパフォーマンスが向上します。

# SREとLLMの関わり

　SRE業務にLLMを導入することで、アラート分析、オペレーション支援、アクセス制御の自動化など、さまざまな領域で効率化が期待されています。ここでは、具体的に私が日々実践しているLLMの活用方法を紹介します。


## アラートの分析

　オンコール対応時に通知されたアラート内容やログ、バックトレース情報をLLMに入力して分析を行います。最新のLLMモデルでは非常に高い精度で解析が可能で、適切な入力を行えば、アラートの直接原因や問題の切り分けに役立つアドバイスが得られます。これにより、特定の問題の対処方法や原因の推測を迅速に行えるようになり、対応時間の短縮に貢献しています。

## オペレーションの補助

　SRE業務では、Infrastructure as Code（IaC）の普及によりインフラ構成をコード化することが標準化しています。LLMは、このようなインフラ定義の作業にも大いに役立っています。

### Terraform定義などの自動生成

　Terraformは、HashiCorpが提供するインフラ構成管理ツールで、インフラのあるべき状態をHashiCorp Configuration Language（HCL）で宣言的に定義し、`apply`コマンドを実行することでインフラを指定の状態に収束させることが可能です。HCLはプログラミング言語に比べシンプルで記号データとしての表現力が限られているため、公開されているサンプルや定義パターンが多く、LLMを用いた自動生成との相性が非常に良いのが特徴です。

　また、`terraform plan`コマンドによって、現在の環境と定義内容の差分を確認できるため、LLMが生成したコードの適用前に変更内容を検証でき、安全性も確保しやすくなっています。これにより、反復的なオペレーションやコードレビューの効率が向上し、SREチームがより複雑なタスクに集中できる環境が整っています。

### afaの紹介

　私の同僚である[@monochromegane](https://x.com/monochromegane)が開発している [afa](https://github.com/monochromegane/afa)について紹介します。afaはコマンドラインで利用可能なAIクライアントで、入力された情報をもとにAIを活用したオペレーションを実行します。たとえば、「カレントディレクトリ配下のtxtファイルの一覧がほしい」といった指示に対し、`find . -name *.txt` というコマンドが返されるイメージです。これは内部でOpenAIの`Structured Output`を利用しており、利用者の工夫次第でさまざまな操作をAIと組み合わせて行うことが可能です。

## 技術の影響範囲の拡張

　ここでは、私自身の実体験から、LLMによる技術の影響範囲の拡張についてお話しします。

### LLMを活用した機械学習によるアクセス制御

　以前、機械学習に関心を持ち、Pythonや数学の技術書を手に学習を進めていましたが、言語や数学への苦手意識、そして実際のアイデア不足もあり、長らく運用サービスで機械学習を活用する機会はありませんでした。しかし、LLMの登場により、機械学習の学習用コードやAPI実装を自動生成できるようになったことで、今年、MLをベースとしたボット判定アルゴリズムを開発するに至りました。

　この仕組みをリリースできたのは、以前から学んでいた「特徴量」の考え方やエンジニアリングの基礎、そしてシステム知識が備わっていたからです。LLMの支援によってアイデアを形にするハードルが大きく下がり、最終的にこのアルゴリズムを完成させることができました。

　このように、LLMの活用により知識があっても実践が難しかった分野も実践に移しやすくなり、エンジニアが新たな技術領域に挑戦するきっかけを得られるようになっています。

# プロンプト・エンジニアリング
　LLM（大規模言語モデル）から最適な答えを引き出すための手段として、近年「プロンプト・エンジニアリング」という手法が注目されています。適切なプロンプトを選び、与えることで、モデルからより精度の高い回答を得る手段としては有用です。

　一方で、「あなたはプロのプログラマです」といった特定のロール（役割）を与えるテクニックについては、慎重な視点が必要だと考えています。LLMの実装や学習プロセスの多くはブラックボックスであり、その内部メカニズムを理解することなく、単に出力結果に依存したテクニックを安易に評価するのは、技術者としての立場からは疑問が残ります。

　技術に基づかず、見かけの成果を強調する手法を「素晴らしいテクニック」として推奨することは、技術者としての本質にそぐわない部分があると感じています。AIを有効に活用するためには、プロンプトの工夫が役立つ一方で、その根本的な仕組みや限界を理解することが重要です。

## 実例：プロのプログラマ
　この例が最適かどうかはさておき、ロールを与えた場合、与えていない場合の出力を示します。

### ロールを与えた場合
　まずはロールを与えた場合の結果です。
#### プロンプト
```
あなたはプロのプログラマです。
下記の実装をリファクタリングしてください。
p (1..10).map { |n| n**n.to_s.reverse.to_i % 11 }.join.chars.uniq.sort
```
#### 結果
```
result = (1..10).map do |n|
  power_result = n**n
  reversed_number = power_result.to_s.reverse.to_i
  reversed_number % 11
end

unique_sorted_chars = result.join.chars.uniq.sort
p unique_sorted_chars

```

### ロールを与えない場合
　次にロールを与えない場合の結果です。
#### プロンプト
```
下記の実装をリファクタリングしてください。
p (1..10).map { |n| n**n.to_s.reverse.to_i % 11 }.join.chars.uniq.sort
```
#### 結果
```
 unique_sorted_chars
result = (1..10).map do |n|
  exponent = n.to_s.reverse.to_i
  n**exponent % 11
end

unique_sorted_digits = result.join.chars.uniq.sort
p unique_sorted_digits
```

　ロールを与えた場合の差分としては、説明変数を使うかどうかという結果になりました。このくらいのスクリプトならば使う、使わないは誤差に思いますが、プロンプト・エンジニアリングのテクニックとしてあげられているものはこういった説明のつかない差分であることがほとんどのように思います。

# エンジニアの生存戦略

　ポストLLM時代において、エンジニアがどのように生き残っていくのかを考察します。

## どのような仕事が残るか？

　「AIが人間の仕事を奪う」と言われて久しいですが、今後も残っていく仕事にはどのようなものがあるでしょうか？例えば、工場の生産ラインはより高度に機械化され、センサー技術とAIの組み合わせによってさらなる自動化が進むと予想されます。それでは、ITエンジニアにはどのような未来が待っているのでしょうか？

### 出力の真贋を見極めるエンジニア

　普段のコーディングやQA業務において、AIが誤った回答をする場面は少なくありません。これは、存在しない情報を提示する「ハルシネーション（幻覚）」が原因の一つです。なぜこのような現象が起こるかというと、LLMは確率をもとに回答を生成するため、文脈にそぐわない情報を含むことがあるからです。このため、LLMを活用する上では、出力された情報の真贋を見極める力が必要不可欠です。

　かつて2ちゃんねる創設者の西村ひろゆき氏が「嘘を見抜けないとインターネットを使うのは難しい」と言ったように、AIを「道具」として使いこなすには正しい知識を持つことが欠かせません。正しい知識がなければ、どれほど優れたツールであっても、その力を十分に引き出すことはできないのです。

### LLMのグルー実装としてのエンジニア

　現状、LLMが能動的に問題を発見し、自律的に行動するには至っていません。多くの場合、人間が何らかの入力を与え、その結果を受け取って次の行動を決定するという形に依存しています。このような状況を見ると、「AIの可能性を引き出すために人間が存在している」かのように思える場面も少なくありません。この段階は過渡期にあると言え、将来的にはセンサー技術や自動化の処理系がさらに発展し、AIが能動的に活動する未来も実現するでしょう。

### 学習データを新たに生み出すためのエンジニア

　ご存知の通り、現在のLLMは、人類が蓄積してきた膨大なデータをもとに学習し、高い精度を獲得しています。私の専門外の分野ではありますが、学習データに基づきAIが新しい発明を生み出す未来は十分にあり得るでしょう。しかし、その場合でもAIが生成した知識や成果を検証し、新たな学習データとして取り込む役割は、引き続きエンジニアが担うと考えられます。また、新しいプログラミング言語や仕組みの開発も、しばらくは人間による創造的な作業が必要であり、エンジニアに求められる領域が残っていくでしょう。

## LLMが今はまだあまり向かないこと

　ここでは、現状のAIでは十分に要件を満たすのが難しいと考えられる分野について述べます。

### バリデーション

　「正しいかどうか」を判断するような問題については、現状のAIではまだ課題が残っています。例えば、Webフォームに入力された住所が実際に存在するか、あるいはフォーマットとして正しいかどうかを判定するような場合、AIは一定の確率で誤った回答を出してしまうことがあります。このように、比較的自明な判定を必要とするケースでは、ルールベースの判定がAIよりも優位なことが多いです。

### 決定の最終判断

　AIによる決定をダブルチェックなしで最終判断とすることにも課題があります。例えば、あなたの給与の振込先をAIに任せるとしたらどうでしょう？非常に練られたプロンプトを与えたとしても、AIの判断に疑念が残るかもしれません。こうした意思決定をすべてAIに委ねるには、まだ解決すべき点が多いのが現状です。

　一方で、金銭的なリスクや生命の危険がないようなケースでは、AIの活用の余地が広がっています。たとえば、SUZURIの推薦機能のように、ユーザーに商品を推薦する際、最終的な購入判断はユーザーに委ねられています。このように、重要な判断は人間が行うという形であれば、AIを十分に活用できる場面が増えつつあります。

## この先LLMはどうなっていくか

　LLMはさらに進化し、エンジニアリングのあらゆる場面で重要な役割を果たすことが予想されます。ここでは、LLMが今後どのような形で利用されていくかについて考えます。

### プラットフォームとしてのLLM

　将来的には、LLMはiOSやAndroid、AWSのように、一つの主要なプラットフォームとして利用される時代が訪れるでしょう。既にOpenAIのAPIやGoogleのGeminiのように、開発者がアクセスしやすい形で提供され、さまざまなアプリケーションやシステムに統合されつつあります。これにより、エンジニアはLLMを使って標準的な機能を実現するだけでなく、特定の課題に対して高度なカスタマイズや最適化ができるようになります。

　また、LLMがプラットフォーム化することで、機械学習の知識がなくても簡単にAIを活用できる環境が広がり、エンジニア以外の職種もLLMを業務に組み込むことが当たり前になるでしょう。LLMは単なる技術から、多くの業務を支える基盤的な存在に発展していくことが期待されます。

### ローカル実行されるLLM

　現在、LLMはクラウドベースで提供されることが主流ですが、今後はローカル環境で実行できる軽量モデルの開発が進むと考えられます。こうしたローカル実行可能なLLMは、データの機密性やリアルタイム処理が求められる場面で特に重宝されるでしょう。プライバシーが重要な領域や、低遅延が求められるIoTデバイス、エッジコンピューティングの分野でもLLMが活用されることで、クラウド依存からの脱却が可能になります。

　また、企業が自社データを安全に利用しながら、LLMをローカルでトレーニング・実行することで、よりカスタマイズされた機能の実現が期待されます。特定分野や用途に特化したローカルLLMの開発が進むことで、あらゆる業界においてLLMの普及がさらに加速するでしょう。

## この先、話し手はどうしていくか

　LLMの進化に伴い、エンジニアとしてどのように対応していくべきかについて考えます。


### 継続的な基礎知識の研鑽

　LLMの活用が進む中で、エンジニアにはAIをただ利用するだけでなく、基礎知識を応用してさらなる成果を生み出す力が求められます。基礎知識があることで、AIによってその力を増幅し、新たな創造や応用が容易に可能になります。そのため、LLM登場以前には手を出さなかった分野にも積極的に触れ、基礎を学び、それをもとにAIを活用して成果を拡大していくことを目指しています。

### プラットフォームとしてのLLM活用

　LLMがプラットフォームとして広く利用される未来において、これを上手く活用するスキルがますます重要になっていくでしょう。これは、ある種の「諦め」や「妥協」とも言えますが、これまでもRDSやKubernetesといった大規模なシステムを自作することを目指さず、既存の英知を活用する方が自身の強みを生かせると理解してきました。LLMについても、今は自ら作ることよりも、プラットフォームとして受け入れ、効率的に活用していくことで、より広い範囲で活躍の機会が得られると考えています。

### 情報の真贋を見る力を養う

　最後に、LLMが生成した情報の真贋を見極める力を養うことが不可欠です。AIが生成する情報が増える中で、誤情報やフェイクが含まれていないかを見抜く力が求められます。これはエンジニアリングに留まらず、物事の良し悪しや価値判断も含めた総合的な視点が必要です。

　何かを類推し価値を判断する力や視点は一日にして身につくものではなく、簡単に習得できるものでもありません。日々自分の判断基準をアップデートし、自分なりの定規を磨き続けることを大切にしていきたいと思っています。
