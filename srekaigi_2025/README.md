## AIへの指示
私がSRE Kaigi 2025で登壇する際のスライドのもととなる原稿です。
表記の揺れを中心に推敲し、内容を厚くしたほうがいいところは補足してください。
また下記は意識してください。

1. スライドの作成は別途やるので筆記形式で書いてください。
2. アウトラインはあんまり変えてほしくないです。
3. 段落の内容については必要に応じて膨らませて下さい。
4. マークダウン・シンタックスで書いてください。

## ここから原稿
---
**タイトル: Re:Define 可用性を支えるモニタリング、パフォーマンス最適化、そしてセキュリティ**


**主張したいこと:**

SREは可用性に対して責務を持つロールである。故に、可用性に関することであれば必要なことはすべてやってもいいという信条がある。しかし、SREの実装にはさまざまな形態があり、たとえば旧来のインフラエンジニアが肩書きを変えてSREと名乗る場合や、DevOpsを実践していたチームがSREと名乗るケースもある。
実装が多様であること自体は問題ではないが、SREとして成すべきことを矮小化せず、「必要なことは何でもやる」という姿勢が重要だと考えている。本稿では、私の個人的な主観を踏まえながら、この点を述べたい。


## Re:Define

Google社をはじめ多くの企業のアウトプットにより、「SREとは何か」ということや、それを実践するためのノウハウがが広く伝えられてきた。そのさまざまな定義やノウハウに対して、「私はこう思う」「こうしている」というアンサーソングとして話したいという意図から、本稿のタイトルに「Re:」を付けた。「Re:」はメールの返信のときに付く「Re:」が元ネタである。


## 哲学

SREとして運用に取り組むときに、私はよく「足し算できるように作る」と言っている。これにはいくつかの意味がある。

1つ目は、未完成でも一定のベネフィットがあるならば先に出してしまうということだ。システム運用はタイムスパンが長いことが多いので、最初から完璧なものを作るよりは、効果のある段階でリリースし、その恩恵を受けながら最終的に100%を目指すほうがうまくいく場合が多い。

2つ目は、たとえば何か障害が発生したときに、オブザーバビリティを高める仕組みや監視ルールを追加して、システムを継続的に育てていくということだ。これは「同じ問題を二度と起こさないために足していく」というニュアンスを含んでいる。

本日はこの哲学に基づき、SREの基礎的な内容に触れつつ、私の経験に基づいたTipsを紹介していきたい。


## SREの定義

Site Reliability Engineering（SRE）は、Googleが提唱した概念である。SRE本では「ソフトウェアエンジニアがシステム運用を行うときにどのようなことが起こるか」という視点で説明されることが多い。

### 可用性とは

可用性とは、そのシステムが利用できるかどうかを示す尺度であり、SREが担保すべきシステム要件の代表例である。後述するセキュリティ特性（機密性・完全性・可用性）の観点においても、可用性は必須の要素だとされている。

### SLI/SLO

#### SLI

SLI（Service Level Indicator）は、可用性のようなシステムの健全性を測る指標である。具体的にはサイトの応答HTTPステータスコード200の割合や、応答レイテンシなどが利用される。

#### SLO

SLO（Service Level Objective）は、SLIをもとにどの程度の可用性を目標とするかを定めたものである。SREはSLOの達成状況を踏まえ、システムの回復行動を取るのか、最適化行動を取るのかといった意思決定を行う。


## 監視

SRE活動の最初のステップになることが多いのが「監視」である。ここでは、監視を行う理由と、何を監視すべきかについて述べる。

### なぜ監視をするのか

監視の目的は、第一にシステムの健全性を測るためである。サービスの可用性を把握するには、まず観測が必要であり、監視なしではシステムがダウンしていても誰も気づけない状態となる。

### 何を監視すべきか？

監視とは、メトリクスを集め、それに基づいてアラートを発生させるなど、人が能動的に行動を起こす仕組みまで含めた一連のプロセスを指す。

#### リソース監視

サーバのCPUやメモリといったベーシックな指標から、近年ではクラウドサービスが提供するメトリクスなども含めて監視対象とすることが多い。

##### CPU使用率95%は異常か？

CPU使用率95%が異常かどうかは、実はコンテキスト次第である。平常時のピークタイムに95%に達していてもレスポンスが遅くならないのであれば正常と言えるし、普段は20%程度なのに突然95%になったのなら異常だと判断できる。また、CPU使用率が高い原因がSQLの遅延であるなど、リソース監視で見えている事象は真因の結果ということも多い。

#### セマンティック監視

ユーザーやビジネスの観点からシステムが正常に動いているかを直接監視する手法である。たとえば「ユーザー登録ができる」「買い物かごに商品が入る」といった機能単位で動作をチェックし、サービスが意図どおり提供されているかを確認する。

##### 合成監視

「トップページにアクセス → ログイン → ページ遷移 → ログアウト」といった一連のユーザー操作をスクリプト化し、定期的に実行することでサービスの稼働状況を確認する。操作フローのどこかが失敗した場合、ユーザーに影響が出ていると判断できる。

### 足し算する監視

たとえば監視の結果、システムがダウンして障害となった場合、その障害の原因となったテレメトリデータを新たに取得し、監視対象を増やすことで障害の感知精度を高める。また、可能ならば同様の障害が起きないような仕組みづくりや、自動復旧の仕掛けを足していくことが望ましい。


## オブザーバビリティ

監視活動の結果として異常や障害を検知した場合、その調査をどれだけ外部からシステムを変更せずに行えるかが重要になる。ここでは、その観点でオブザーバビリティについて解説する。

### オブザーバビリティの高いシステム

オブザーバビリティが高いシステムとは、外部からシステムに手を入れなくても「今システムの内部で何が起きているか」が分かることを指す。たとえば、詳細なログやメトリクスがあれば、コードを修正してデバッグ情報を仕込まなくても問題の原因を追える。

### テレメトリーデータ

オブザーバビリティを高める手段として、適切な箇所・粒度でテレメトリーデータ（ログ、メトリクス、トレース）を取得する必要がある。これらを多角的に収集することで、システムの外部から状態を把握できるようになる。

### 足し算するオブザーバビリティの向上

監視と同様に、何か障害が起きたときに新しくメトリクス計測を追加したり、トレースの取得箇所を増やしたり、ログを増やしたりすることで、日々オブザーバビリティを高めることができる。


## 監視/オブザーバビリティのバッドノウハウ

ここからは、これまでに挙げた監視やオブザーバビリティ向上の取り組みが、うまくいっていないケースを紹介する。

### 監視ルールが適切ではなくノイジーアラートが多発

監視アラートが発生しても誰も対応しなくても問題ないものや、システムの可用性にまったく関係ないものがアラートになっているケースをよく見かける。こうしたノイズを放置すると、本当に重要なアラートを見逃してしまう可能性が高まる。不要なアラートは積極的に消し込み、必要なアラートだけが残る状態にすることが重要だ。

### アラート対応が人海戦術になっている

監視アラートが発生しても、対応者が根本的に修復できる権限や知識を持たず、毎回同じ対応を繰り返すだけになっているケースがある。これはSREにおける「トイル（Toil）」の典型例であり、適切なエスカレーションフローや自動化によって解消することが望ましい。

#### トイルとはなにか

トイルとは、必要ではあるが長期的なシステム運用における価値を生み出さない作業を指す。たとえば、ファイルシステムが溢れたら毎回同じファイルを手動で削除するといった行為が典型的である。

#### unknown/unknown

「知らないことを知らない」状態を指す。初学者にとっては、ファイルシステムがいっぱいになるアラートに対してファイルを削除する以外の選択肢を知らない場合がある。しかし、熟練エンジニアであれば、そもそもファイルを浪費しないプロセスに変える、cronを用いて自動的に削除するなどの解決策を提案できるかもしれない。そういった知識差により、問題の根本的解決ができないままトイルが続いてしまうことがある。

## **パフォーマンス・チューニング**

SREの重要な仕事の一つとして、パフォーマンス・チューニングが挙げられる。

### **なぜパフォーマンス・チューニングが必要か**

非日常的なトラフィックの増大や、不具合による処理性能の悪化などにより、最悪システムダウンが発生すると可用性が損なわれる。そのため、SREとしてパフォーマンス面のリスクを常に監視し、問題があれば改善を行うことが非常に重要である。

### **パフォーマンス・チューニングにおけるジレンマ**

パフォーマンス改善の調査をSREが担当しても、実際のコード改修は開発チームに任される場合が多い。その際、開発チームの優先度が新機能開発に置かれると、パフォーマンスの改善や可用性の担保が後回しになるケースがある。このような状況に対応するには、以下の2点に取り組む必要がある。

#### **1. SREの取り組みを組織的なものにする**

可用性が落ちている状態は、サービスが利用できないことを意味する。どんなに新機能を作っても、ユーザーに使われない新機能はその時点で価値を生み出さない。ゆえに、可用性の担保はSREだけでなく、開発者や管理者を含めた組織全体の責務となる。管理者や経営層を含めた優先度の調整・合意形成が不可欠だ。

#### **2. 全部やればええやろ**

開発チームがなかなか動かない場合であっても、SREが自ら問題を解決できるなら、ユーザー視点では問題が解消される。可能な範囲でSREが主体的にコードや設定変更を行い、システムの可用性やパフォーマンスを改善するアプローチも考えられる。


### **どうすればSREがパフォーマンス・チューニングできるようになるのか**

国内のSREは歴史が浅く、従来のインフラチームや開発チームからスピンオフしたなど、さまざまな形態が存在する。ここでは、実装形態に左右されない普遍的な考え方を示す。

#### **計算量で考える**

よくあるスロークエリやN+1問題は、必要以上に多くの計算資源を浪費しているケースが多い。スロークエリは過剰なテーブル走査が原因であることが多く、N+1問題は不要なクエリを繰り返し実行しているだけとも言える。
根本的には「計算量を削減する」という視点が重要であり、アルゴリズムやデータ構造の知識を身につけることで、ボトルネックに気づきやすくなる。

#### **道具を磨く**

ここで言う道具はエディターや、Linuxコマンド、SaaSなどの仕事道具を指します。エディタの設定を作り込みタグジャンプできるようにして、コードを置いやすくするとか、straceやtcpdumpなどのLinuxコマンドを使いこなすことで、システムの内部動作を観察できるようになる。また、SaaSを使いこなすことで、監視やログ収集を効率化することも可能だ。こういった道具を使いこなすことで、パフォーマンス問題の解決に迅速に対応できるようになる。

#### **引き出しを増やす**

計算量の問題を把握できたとしても、それを改善する手法を知らなければ解決には至らない。たとえばデータベースであれば、インデックスの貼り方やSQLの書き方、ER図の読み解き方などの知識が必要だ。HTTPリクエストが遅延しているならばキャッシュ戦略を取ったり、通信失敗が多いなら指数バックオフリトライを導入するといった実装パターンも考えられる。
このように「技術の引き出し」を豊富に持っておくことで、様々なパフォーマンス問題を柔軟に解決できるようになる。

#### **Linuxの仕組みを理解する**
例えばカーネルチューニングや、プロセス間通信の仕組みを理解することで、システム全体のパフォーマンスを向上させることができる。またカーネルチューニングでよく触る値はバッファーなどのパラメーターが多く、そういったパラメーターの意味や仕組みを理解することで、間接的にプログラムやシステムの挙動にも精通できるようになる。それはLinuxですらもソフトウェアであり、現代のあらゆるソフトが動く基盤であるLinuxにはソフトウェアのナレッジが詰め込まれている。Linuxを学ぶことで増える引き出しも多くあるので、ぜひ数冊の本を手にとって見てほしい。

#### **ルールチェンジする柔軟な発想を持つ**

特例的な例だが、根本的に「処理を速くする」以外のアプローチを取る柔軟さも必要だ。たとえば仮想待合室のようにユーザーアクセス数そのものをコントロールする仕組みを導入したり、サービスのフローを大きく変えて負荷を分散するなど、「スループットを物理的に抑制する」方向の施策もパフォーマンス問題の解決に有効である。


### **趣味開発を通じたスキル向上**

ここまで挙げた方法論を身につけるには、実際に自分でサービスを作り、運用を体験するのが効率がいい。昨今はAIなどを活用すれば、対話的に学習しながら簡単なWebアプリケーションを構築することも難しくない。
ブログシステム程度であっても、Web表示からDBへの書き込みまで一通り実装してみると、驚くほど多くの学びが得られる。ライブラリの問題点を深堀りする機会にもなり、時には本当に不具合を見つけてしまうこともある。SREだからこそ、趣味開発を通じて開発スキルを伸ばすのは非常におすすめである。

## セキュリティ

SREの重要な仕事のひとつとしてセキュリティに対する取り組みがあります。
セキュリティインシデントは、最悪の場合サービスの終了を招くこともあり、可用性どころか全てが無に帰るリスクがあります。
SREとして、どのようにセキュリティの取り組みを進めるべきかについて、予防策と発生時の対応策に分けて具体例を紹介します。

### セキュリティインシデントを発生させないために

セキュリティインシデントを未然に防ぐため、SREが日々実践すべき取り組みを以下に示します。

#### シフトレフト

- **構成管理のガードレール整備**
  インフラ構成管理において、意図しないホストやポートの公開がないか、コンテナの権限が適切かをワークフローで検知し、自動修正する仕組みを構築します。
  アプリケーションエンジニアがクラウドサービスの設定を行うことも増えているため、誰が作業しても問題が発生しない自動化の実現が重要です。

- **ヒヤリハットのコード化**
  小さなミスやインシデント予兆を放置せず、それをコード化する文化を構築します。
  たとえば、「この変更が原因で一度問題が起きた」という教訓をガードレールに反映させ、再発を防ぎます。

- **AIを活用したレビューの導入**
  昨今、AIを利用してコードや構成ファイルの自動レビューが可能になっています。
  インシデントリスクを低減するため、こうしたツールの導入を検討してください。

#### ソフトウェアのバージョンアップ

- **脆弱性の放置リスク**
  脆弱性を探索するボットが広く存在し、更新が遅れたソフトウェアが攻撃対象になるケースが増えています。
  これを防ぐために、DependabotやRenovateなどのツールを利用し、自動的にライブラリやパッケージを更新します。

- **OSレベルの対策**
  Linuxディストリビューションが提供する自動アップデート機能を利用し、OSの脆弱性も継続的に修正します。

#### 異常・変更検知

- **異常検知システムの導入**
  システムに異常な振る舞いがないか、例えば意図しないデータの流出やネットワーク通信を検知する仕組みを整備します。
  特に、普段通信しない経路への通信を遮断するネットワーク監視ツールが有効です。

- **変更検知の強化**
  ファイル配置やプロセス変更をリアルタイムで監視し、意図しない変更があった場合には即座にアラートを発する仕組みを構築します。

- **誤検知対策**
  正常なデプロイであってもアラートが発生する場合があるため、ノイジーアラートを除外するための簡易なルール設定機能を実装します。

#### 脆弱性診断

- **定期診断の重要性**
  システムは常に変化しており、意図しない脆弱性が混入するリスクがあります。
  社内のセキュリティチームや外部ベンダーを活用し、定期的に脆弱性診断を実施してください。

- **診断結果からの学び**
  実際の診断で検知された脆弱性は、自チームが想定していなかった攻撃手法に基づいていることが多いです。
  これらを積極的に取り込み、セキュリティ体制を強化します。

### セキュリティインシデントが発生してしまった時のために

セキュリティ対策をどれだけ講じても、攻撃手法の高度化により防げないケースがあります。
インシデントが発生した際、迅速に対応するための取り組みを以下に示します。

#### 影響範囲を特定するための情報保全

- **ログの保全**
  監査ログやデータベースクエリログを収集し、攻撃者による改ざんを防ぐために外部システムに保存します。
  これにより、何が起きたのかを調査しやすくなります。

- **ストリーミングの活用**
  特に重要なログはストリーミングで即時に保全し、影響範囲の特定に役立てます。

#### 利用できるバックアップを確保する

- **ランサムウェア対策**
  ランサムウェア攻撃を受けた場合に備え、暗号化されていない状態のバックアップを確保します。
  ゼロからの復旧を避けるため、定期的なバックアップと検証を行います。

- **リストアの検証**
  バックアップデータが有効かどうか、定期的にリストアテストを実施します。
  これを自動化することで、復旧可能性を常に維持します。

#### インシデント訓練を実施する

- **実践的なシミュレーション**
  攻撃を想定したインシデント対応訓練を実施します。
  例えば、攻撃が進行中のシナリオを用意し、影響範囲の特定、復旧手順の確認を行います。

- **外部サービスの活用**
  Chaos Engineeringやセキュリティ訓練を支援するプラットフォームを導入し、より実践的なスキル向上を図ります。


