## AIへの指示
私がSRE Kaigi 2025で登壇する際のスライドのもととなる原稿です。
表記の揺れを中心に推敲し、内容を厚くしたほうがいいところは補足してください。
また下記は意識してください。

1. スライドの作成は別途やるので筆記形式で書いてください。
2. アウトラインはあんまり変えてほしくないです。
3. マークダウンシンタックスで書いてください。

## ここから原稿

**タイトル: Re:Define 可用性を支えるモニタリング、パフォーマンス最適化、そしてセキュリティ**

---

**主張したいこと:**

SREは可用性に対して責務を持つロールである。故に、可用性に関することであれば必要なことはすべてやってもいいという信条がある。しかし、SREの実装にはさまざまな形態があり、たとえば旧来のインフラエンジニアが肩書きを変えてSREと名乗る場合や、DevOpsを実践していたチームがSREと名乗るケースもある。  
実装が多様であること自体は問題ではないが、SREとして成すべきことを矮小化せず、「必要なことは何でもやる」という姿勢が重要だと考えている。本稿では、私の個人的な主観を踏まえながら、この点を述べたい。

---

## Re:Define

Google社をはじめ多くの企業のアウトプットにより、「SREとは何か」が広く伝えられてきた。そのさまざまな定義に対して、「私はこう思う」「こうしている」というアンサーソングとして話したいという意図から、本稿のタイトルに「Re:」を付けた。「Re:」はメールの返信のときに付く「Re:」が元ネタである。

---

## 哲学

SREとして運用に取り組むときに、私はよく「足し算できるように作る」と言っている。これにはいくつかの意味がある。

1つ目は、未完成でも一定のベネフィットがあるならば先に出してしまうということだ。システム運用はタイムスパンが長いことが多いので、最初から完璧なものを作るよりは、効果のある段階でリリースし、その恩恵を受けながら最終的に100%を目指すほうがうまくいく場合が多い。

2つ目は、たとえば何か障害が発生したときに、オブザーバビリティを高める仕組みや監視ルールを追加して、システムを継続的に育てていくということだ。これは「同じ問題を二度と起こさないために足していく」というニュアンスを含んでいる。

本日はこの哲学に基づき、SREの基礎的な内容に触れつつ、私の経験に基づいたTipsを紹介していきたい。

---

## SREの定義

Site Reliability Engineering（SRE）は、Googleが提唱した概念である。SRE本では「ソフトウェアエンジニアがシステム運用を行うときにどのようなことが起こるか」という視点で説明されることが多い。

### 可用性とは

可用性とは、そのシステムが利用できるかどうかを示す尺度であり、SREが担保すべきシステム要件の代表例である。後述するセキュリティ特性（機密性・完全性・可用性）の観点においても、可用性は必須の要素だとされている。

### SLI/SLO

#### SLI

SLI（Service Level Indicator）は、可用性のようなシステムの健全性を測る指標である。具体的にはサイトの応答HTTPステータスコード200の割合や、応答レイテンシなどが利用される。

#### SLO

SLO（Service Level Objective）は、SLIをもとにどの程度の可用性を目標とするかを定めたものである。SREはSLOの達成状況を踏まえ、システムの回復行動を取るのか、最適化行動を取るのかといった意思決定を行う。

---

## 監視

SRE活動の最初のステップになることが多いのが「監視」である。ここでは、監視を行う理由と、何を監視すべきかについて述べる。

### なぜ監視をするのか

監視の目的は、第一にシステムの健全性を測るためである。サービスの可用性を把握するには、まず観測が必要であり、監視なしではシステムがダウンしていても誰も気づけない状態となる。

### 何を監視すべきか？

監視とは、メトリクスを集め、それに基づいてアラートを発生させるなど、人が能動的に行動を起こす仕組みまで含めた一連のプロセスを指す。

#### リソース監視

サーバのCPUやメモリといったベーシックな指標から、近年ではクラウドサービスが提供するメトリクスなども含めて監視対象とすることが多い。

##### CPU使用率95%は異常か？

CPU使用率95%が異常かどうかは、実はコンテキスト次第である。平常時のピークタイムに95%に達していてもレスポンスが遅くならないのであれば正常と言えるし、普段は20%程度なのに突然95%になったのなら異常だと判断できる。また、CPU使用率が高い原因がSQLの遅延であるなど、リソース監視で見えている事象は真因の結果ということも多い。

#### セマンティック監視

ユーザーやビジネスの観点からシステムが正常に動いているかを直接監視する手法である。たとえば「ユーザー登録ができる」「買い物かごに商品が入る」といった機能単位で動作をチェックし、サービスが意図どおり提供されているかを確認する。

##### 合成監視

「トップページにアクセス → ログイン → ページ遷移 → ログアウト」といった一連のユーザー操作をスクリプト化し、定期的に実行することでサービスの稼働状況を確認する。操作フローのどこかが失敗した場合、ユーザーに影響が出ていると判断できる。

### 足し算する監視

たとえば監視の結果、システムがダウンして障害となった場合、その障害の原因となったテレメトリデータを新たに取得し、監視対象を増やすことで障害の感知精度を高める。また、可能ならば同様の障害が起きないような仕組みづくりや、自動復旧の仕掛けを足していくことが望ましい。

---

## オブザーバビリティ

監視活動の結果として異常や障害を検知した場合、その調査をどれだけ外部からシステムを変更せずに行えるかが重要になる。ここでは、その観点でオブザーバビリティについて解説する。

### オブザーバビリティの高いシステム

オブザーバビリティが高いシステムとは、外部からシステムに手を入れなくても「今システムの内部で何が起きているか」が分かることを指す。たとえば、詳細なログやメトリクスがあれば、コードを修正してデバッグ情報を仕込まなくても問題の原因を追える。

### テレメトリーデータ

オブザーバビリティを高める手段として、適切な箇所・粒度でテレメトリーデータ（ログ、メトリクス、トレース）を取得する必要がある。これらを多角的に収集することで、システムの外部から状態を把握できるようになる。

### 足し算するオブザーバビリティの向上

監視と同様に、何か障害が起きたときに新しくメトリクス計測を追加したり、トレースの取得箇所を増やしたり、ログを増やしたりすることで、日々オブザーバビリティを高めることができる。

---

## Bad 監視/オブザーバビリティ

ここからは、これまでに挙げた監視やオブザーバビリティ向上の取り組みが、うまくいっていないケースを紹介する。

### 監視ルールが適切ではなくノイジーアラートが多発

監視アラートが発生しても誰も対応しなくても問題ないものや、システムの可用性にまったく関係ないものがアラートになっているケースをよく見かける。こうしたノイズを放置すると、本当に重要なアラートを見逃してしまう可能性が高まる。不要なアラートは積極的に消し込み、必要なアラートだけが残る状態にすることが重要だ。

### アラート対応が人海戦術になっている

監視アラートが発生しても、対応者が根本的に修復できる権限や知識を持たず、毎回同じ対応を繰り返すだけになっているケースがある。これはSREにおける「トイル（Toil）」の典型例であり、適切なエスカレーションフローや自動化によって解消することが望ましい。

#### トイルとはなにか

トイルとは、必要ではあるが長期的なシステム運用における価値を生み出さない作業を指す。たとえば、ファイルシステムが溢れたら毎回同じファイルを手動で削除するといった行為が典型的である。

#### unknown/unknown

「知らないことを知らない」状態を指す。初学者にとっては、ファイルシステムがいっぱいになるアラートに対してファイルを削除する以外の選択肢を知らない場合がある。しかし、熟練エンジニアであれば、そもそもファイルを浪費しないプロセスに変える、cronを用いて自動的に削除するなどの解決策を提案できるかもしれない。そういった知識差により、問題の根本的解決ができないままトイルが続いてしまうことがある。
